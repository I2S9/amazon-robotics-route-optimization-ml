{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Génération de Données ML pour l'Optimisation de Routes\n",
        "\n",
        "Ce notebook génère un dataset synthétique pour entraîner un modèle de Machine Learning capable de prédire le temps de trajet dans un entrepôt Amazon.\n",
        "\n",
        "## Objectifs\n",
        "\n",
        "1. **Simuler différentes configurations d'entrepôt** :\n",
        "   - Congestion (densité de robots)\n",
        "   - Obstacles (cases bloquées)\n",
        "   - Vitesse variable selon les conditions\n",
        "\n",
        "2. **Collecter des features** :\n",
        "   - Coordonnées de départ et d'arrivée\n",
        "   - Distance euclidienne\n",
        "   - Niveau de congestion\n",
        "   - Présence d'obstacles\n",
        "   - Nombre de robots\n",
        "\n",
        "3. **Générer des targets** :\n",
        "   - Temps de trajet prédit (`predicted_time`)\n",
        "\n",
        "4. **Créer un dataset équilibré** (1000-10000 lignes) pour l'entraînement ML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src directory to path\n",
        "sys.path.insert(0, os.path.join('..', 'src'))\n",
        "\n",
        "from utils import euclidean_distance\n",
        "from generate_ml_data import MLDataGenerator\n",
        "\n",
        "# Configuration\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except:\n",
        "    plt.style.use('seaborn')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Imports réussis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initialisation du Générateur de Données\n",
        "\n",
        "Nous créons un générateur qui va simuler différents scénarios d'entrepôt avec :\n",
        "- **Congestion** : Plus il y a de robots, plus la congestion augmente\n",
        "- **Obstacles** : Cases bloquées qui ralentissent les robots\n",
        "- **Vitesse variable** : Le temps de trajet dépend de la distance, congestion et obstacles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Créer le générateur de données ML\n",
        "generator = MLDataGenerator(\n",
        "    grid_size=(20, 20),      # Entrepôt 20×20\n",
        "    n_samples=5000,           # 5000 échantillons\n",
        "    random_seed=42           # Pour reproductibilité\n",
        ")\n",
        "\n",
        "print(f\"Générateur initialisé :\")\n",
        "print(f\"  - Taille de l'entrepôt : {generator.grid_size}\")\n",
        "print(f\"  - Nombre d'échantillons : {generator.n_samples}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Génération du Dataset avec Plusieurs Scénarios\n",
        "\n",
        "Nous générons un dataset avec des configurations variées pour tester différents scénarios :\n",
        "- **Nombre de robots** : 1 à 10 (variation pour tester différents niveaux de congestion)\n",
        "- **Densité d'obstacles** : 0% à 20% (variation pour tester l'impact des obstacles)\n",
        "- **Congestion équilibrée** : Distribution uniforme sur 10 niveaux (0.0 à 1.0) pour tester tous les niveaux\n",
        "- **Points de départ/arrivée** : Aléatoires dans l'entrepôt (variation des distances)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Générer le dataset\n",
        "print(\"Génération du dataset en cours...\")\n",
        "df = generator.generate_dataset(\n",
        "    n_robots_range=(1, 10),              # Entre 1 et 10 robots\n",
        "    obstacle_density_range=(0.0, 0.2),    # 0% à 20% d'obstacles\n",
        "    balance_congestion=True               # Distribution équilibrée\n",
        ")\n",
        "\n",
        "print(f\"Dataset généré : {len(df)} échantillons\")\n",
        "print(f\"\\nColonnes : {', '.join(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploration et Analyse du Dataset\n",
        "\n",
        "Analysons la structure et les statistiques du dataset généré.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aperçu du dataset\n",
        "print(\"=\" * 60)\n",
        "print(\"APERÇU DU DATASET\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape : {df.shape}\")\n",
        "print(f\"\\nPremières lignes :\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistiques descriptives\n",
        "print(\"=\" * 60)\n",
        "print(\"STATISTIQUES DESCRIPTIVES\")\n",
        "print(\"=\" * 60)\n",
        "df.describe()\n",
        "\n",
        "# Vérification de la cohérence des colonnes\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VÉRIFICATION DE LA COHÉRENCE DES COLONNES\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Nombre de colonnes : {len(df.columns)}\")\n",
        "print(f\"Types de données :\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nValeurs manquantes :\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nPlages de valeurs :\")\n",
        "for col in df.columns:\n",
        "    if df[col].dtype in ['float64', 'int64']:\n",
        "        print(f\"  {col}: [{df[col].min():.2f}, {df[col].max():.2f}]\")\n",
        "    else:\n",
        "        print(f\"  {col}: {df[col].unique()[:5]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test des Niveaux de Congestion\n",
        "\n",
        "Testons et vérifions que tous les niveaux de congestion sont bien représentés dans le dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution de la congestion\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogramme\n",
        "axes[0].hist(df['congestion'], bins=20, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Niveau de Congestion', fontsize=12)\n",
        "axes[0].set_ylabel('Fréquence', fontsize=12)\n",
        "axes[0].set_title('Distribution de la Congestion', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Comptage par niveau\n",
        "congestion_counts = df['congestion'].value_counts().sort_index()\n",
        "axes[1].bar(range(len(congestion_counts)), congestion_counts.values, \n",
        "            color='steelblue', edgecolor='black', alpha=0.7)\n",
        "axes[1].set_xlabel('Niveau de Congestion (discret)', fontsize=12)\n",
        "axes[1].set_ylabel('Nombre d\\'échantillons', fontsize=12)\n",
        "axes[1].set_title('Distribution Discrète de la Congestion', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xticks(range(len(congestion_counts)))\n",
        "axes[1].set_xticklabels([f'{val:.2f}' for val in congestion_counts.index], rotation=45)\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Distribution de la congestion :\")\n",
        "print(congestion_counts)\n",
        "print(f\"\\nDataset équilibré : {len(congestion_counts)} niveaux de congestion\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyse des Obstacles\n",
        "\n",
        "Vérifions la distribution des obstacles dans le dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution des obstacles\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Pie chart\n",
        "obstacle_counts = df['has_obstacles'].value_counts()\n",
        "labels = ['Sans obstacles', 'Avec obstacles']\n",
        "colors = ['lightgreen', 'lightcoral']\n",
        "axes[0].pie(obstacle_counts.values, labels=labels, autopct='%1.1f%%', \n",
        "            colors=colors, startangle=90, textprops={'fontsize': 12})\n",
        "axes[0].set_title('Distribution des Chemins\\n(Avec/Sans Obstacles)', \n",
        "                  fontsize=14, fontweight='bold')\n",
        "\n",
        "# Histogramme de la densité d'obstacles\n",
        "axes[1].hist(df['obstacle_density'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "axes[1].set_xlabel('Densité d\\'Obstacles', fontsize=12)\n",
        "axes[1].set_ylabel('Fréquence', fontsize=12)\n",
        "axes[1].set_title('Distribution de la Densité d\\'Obstacles', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Statistiques obstacles :\")\n",
        "print(f\"  - Chemins avec obstacles : {df['has_obstacles'].sum()} ({100*df['has_obstacles'].mean():.1f}%)\")\n",
        "print(f\"  - Chemins sans obstacles : {(~df['has_obstacles'].astype(bool)).sum()} ({100*(1-df['has_obstacles'].mean()):.1f}%)\")\n",
        "print(f\"  - Densité moyenne : {df['obstacle_density'].mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyse de la Variable Cible (predicted_time)\n",
        "\n",
        "Analysons la distribution du temps de trajet prédit et sa relation avec les features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution du temps de trajet\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Histogramme\n",
        "axes[0, 0].hist(df['predicted_time'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "axes[0, 0].set_xlabel('Temps de Trajet Prédit', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Fréquence', fontsize=12)\n",
        "axes[0, 0].set_title('Distribution du Temps de Trajet', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Box plot\n",
        "axes[0, 1].boxplot(df['predicted_time'], vert=True)\n",
        "axes[0, 1].set_ylabel('Temps de Trajet Prédit', fontsize=12)\n",
        "axes[0, 1].set_title('Box Plot du Temps de Trajet', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Relation distance vs temps\n",
        "axes[1, 0].scatter(df['distance'], df['predicted_time'], alpha=0.5, s=20, color='steelblue')\n",
        "axes[1, 0].set_xlabel('Distance', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Temps de Trajet Prédit', fontsize=12)\n",
        "axes[1, 0].set_title('Distance vs Temps de Trajet', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Relation congestion vs temps\n",
        "axes[1, 1].scatter(df['congestion'], df['predicted_time'], alpha=0.5, s=20, color='coral')\n",
        "axes[1, 1].set_xlabel('Niveau de Congestion', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Temps de Trajet Prédit', fontsize=12)\n",
        "axes[1, 1].set_title('Congestion vs Temps de Trajet', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Statistiques du temps de trajet :\")\n",
        "print(f\"  - Moyenne : {df['predicted_time'].mean():.2f}\")\n",
        "print(f\"  - Médiane : {df['predicted_time'].median():.2f}\")\n",
        "print(f\"  - Écart-type : {df['predicted_time'].std():.2f}\")\n",
        "print(f\"  - Min : {df['predicted_time'].min():.2f}\")\n",
        "print(f\"  - Max : {df['predicted_time'].max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Validation des Données et Cohérence des Colonnes\n",
        "\n",
        "Vérifions que toutes les valeurs sont logiques et cohérentes :\n",
        "- `travel_time >= distance / max_speed` (le temps ne peut pas être inférieur au minimum théorique)\n",
        "- Cohérence entre les colonnes (ex: distance calculée correctement, obstacles cohérents avec obstacle_density)\n",
        "- Pas de valeurs aberrantes ou incohérentes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation : travel_time >= distance / max_speed\n",
        "max_speed = 1.5  # Vitesse maximale (1.5x la vitesse de base)\n",
        "min_time = df['distance'] / max_speed\n",
        "invalid_samples = (df['predicted_time'] < min_time).sum()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDATION DES DONNÉES\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Échantillons valides : {len(df) - invalid_samples} ({100*(len(df)-invalid_samples)/len(df):.1f}%)\")\n",
        "if invalid_samples > 0:\n",
        "    print(f\"Échantillons invalides : {invalid_samples} ({100*invalid_samples/len(df):.1f}%)\")\n",
        "else:\n",
        "    print(f\"Tous les échantillons sont valides !\")\n",
        "\n",
        "# Vérification de la cohérence des colonnes\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"VÉRIFICATION DE LA COHÉRENCE DES COLONNES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Vérifier que distance correspond bien à la distance euclidienne\n",
        "calculated_distances = np.sqrt((df['end_x'] - df['start_x'])**2 + (df['end_y'] - df['start_y'])**2)\n",
        "distance_diff = np.abs(df['distance'] - calculated_distances)\n",
        "print(f\"Vérification distance : max différence = {distance_diff.max():.6f} (devrait être ~0)\")\n",
        "\n",
        "# Vérifier que has_obstacles est cohérent avec obstacle_density\n",
        "print(f\"Vérification obstacles :\")\n",
        "print(f\"  - Chemins avec obstacles (has_obstacles=1) : {df[df['has_obstacles']==1]['obstacle_density'].mean():.3f} densité moyenne\")\n",
        "print(f\"  - Chemins sans obstacles (has_obstacles=0) : {df[df['has_obstacles']==0]['obstacle_density'].mean():.3f} densité moyenne\")\n",
        "\n",
        "# Vérifier que congestion est dans [0, 1]\n",
        "congestion_valid = ((df['congestion'] >= 0) & (df['congestion'] <= 1)).all()\n",
        "print(f\"Vérification congestion : valeurs dans [0, 1] = {congestion_valid}\")\n",
        "\n",
        "# Vérifier que n_robots est dans la plage attendue\n",
        "robots_valid = ((df['n_robots'] >= 1) & (df['n_robots'] <= 10)).all()\n",
        "print(f\"Vérification n_robots : valeurs dans [1, 10] = {robots_valid}\")\n",
        "\n",
        "# Visualisation de la validation\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Graphique distance vs temps\n",
        "axes[0].scatter(df['distance'], df['predicted_time'], alpha=0.5, s=20, \n",
        "          label='Temps de trajet prédit', color='steelblue')\n",
        "axes[0].plot(df['distance'], min_time, 'r--', linewidth=2, \n",
        "       label=f'Temps minimum théorique (vitesse max = {max_speed}x)')\n",
        "axes[0].set_xlabel('Distance', fontsize=12)\n",
        "axes[0].set_ylabel('Temps de Trajet', fontsize=12)\n",
        "axes[0].set_title('Validation : Temps de Trajet vs Distance Minimum', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(fontsize=11)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Graphique cohérence distance calculée vs distance stockée\n",
        "axes[1].scatter(df['distance'], calculated_distances, alpha=0.5, s=20, color='green')\n",
        "axes[1].plot([df['distance'].min(), df['distance'].max()], \n",
        "            [df['distance'].min(), df['distance'].max()], 'r--', linewidth=2, label='Ligne parfaite')\n",
        "axes[1].set_xlabel('Distance stockée', fontsize=12)\n",
        "axes[1].set_ylabel('Distance calculée', fontsize=12)\n",
        "axes[1].set_title('Cohérence : Distance Stockée vs Calculée', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(fontsize=11)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Matrice de Corrélation\n",
        "\n",
        "Analysons les corrélations entre les features et la variable cible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrice de corrélation\n",
        "correlation_cols = ['distance', 'congestion', 'has_obstacles', 'n_obstacles_near', \n",
        "                    'n_robots', 'obstacle_density', 'predicted_time']\n",
        "corr_matrix = df[correlation_cols].corr()\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Matrice de Corrélation des Features', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Corrélations avec predicted_time :\")\n",
        "correlations = corr_matrix['predicted_time'].sort_values(ascending=False)\n",
        "for feature, corr in correlations.items():\n",
        "    if feature != 'predicted_time':\n",
        "        print(f\"  - {feature}: {corr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Sauvegarde du Dataset\n",
        "\n",
        "Sauvegardons le dataset dans `data/raw/` pour l'étape suivante (entraînement ML).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarder le dataset\n",
        "output_path = generator.save_dataset(df, output_dir=\"../data/raw\")\n",
        "print(f\"Dataset sauvegardé : {output_path}\")\n",
        "print(f\"\\nRésumé final :\")\n",
        "print(f\"  - Nombre d'échantillons : {len(df)}\")\n",
        "print(f\"  - Nombre de features : {len(df.columns) - 1}\")\n",
        "print(f\"  - Variable cible : predicted_time\")\n",
        "print(f\"  - Taille du fichier : {os.path.getsize(output_path) / 1024:.1f} KB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Le dataset contient :\n",
        "- **4,991 échantillons** avec 11 colonnes (10 features + 1 target)\n",
        "- **Distribution équilibrée** de la congestion (10 niveaux)\n",
        "- **Valeurs logiques** : tous les temps de trajet sont >= temps minimum théorique\n",
        "- **Features variées** : distance, congestion, obstacles, nombre de robots, etc.\n",
        "\n",
        "Le dataset est prêt pour l'entraînement d'un modèle ML dans l'étape suivante (prédiction du temps de trajet).\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
