{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 5 — Intégration ML + OR-Tools\n",
    "\n",
    "Ce notebook intègre le modèle ML entraîné à l'étape 4 dans l'optimisation des routes avec OR-Tools.\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Utiliser les prédictions ML (temps de trajet prédit) au lieu de la distance brute pour optimiser les routes, permettant de :\n",
    "- Éviter les chemins congestionnés\n",
    "- Prendre en compte les obstacles\n",
    "- Optimiser le temps réel plutôt que la distance\n",
    "\n",
    "## Étapes\n",
    "\n",
    "1. Charger le modèle ML et les données de l'entrepôt\n",
    "2. Construire une nouvelle matrice de coûts basée sur `predicted_time` au lieu de `distance`\n",
    "3. Relancer l'optimisation OR-Tools avec cette nouvelle matrice\n",
    "4. Comparer les routes avec et sans ML\n",
    "5. Analyser les métriques et les différences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "\n",
    "from optimize_routes import RouteOptimizer, load_warehouse_data\n",
    "from utils import euclidean_distance\n",
    "\n",
    "# Configuration\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Imports réussis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Données et du Modèle ML\n",
    "\n",
    "Chargement :\n",
    "- Données de l'entrepôt (points, labels)\n",
    "- Matrice de distances originale\n",
    "- Modèle ML entraîné\n",
    "- Métriques du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données de l'entrepôt\n",
    "print(\"=\" * 60)\n",
    "print(\"CHARGEMENT DES DONNÉES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "distance_matrix, points, point_labels = load_warehouse_data(data_dir=\"../data/raw\")\n",
    "print(f\"Points chargés : {len(points)}\")\n",
    "print(f\"Matrice de distances : {distance_matrix.shape}\")\n",
    "\n",
    "# Charger le modèle ML\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHARGEMENT DU MODÈLE ML\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "metrics_path = \"../data/processed/ml_model_metrics.json\"\n",
    "with open(metrics_path, 'r') as f:\n",
    "    ml_metrics = json.load(f)\n",
    "\n",
    "model_type = ml_metrics['model']\n",
    "print(f\"Modèle sélectionné : {model_type}\")\n",
    "\n",
    "if model_type == \"Random Forest\":\n",
    "    model_path = \"../data/processed/ml_model_rf.pkl\"\n",
    "    ml_model = joblib.load(model_path)\n",
    "    scaler = None\n",
    "    print(f\"Modèle Random Forest chargé : {model_path}\")\n",
    "else:\n",
    "    model_path = \"../data/processed/ml_model_mlp.pkl\"\n",
    "    scaler_path = \"../data/processed/ml_scaler.pkl\"\n",
    "    ml_model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    print(f\"Modèle MLP chargé : {model_path}\")\n",
    "    print(f\"Scaler chargé : {scaler_path}\")\n",
    "\n",
    "print(f\"\\nPerformances du modèle :\")\n",
    "print(f\"  R² : {ml_metrics['test_r2']:.3f}\")\n",
    "print(f\"  RMSE : {ml_metrics['test_rmse']:.2f}\")\n",
    "print(f\"  MAE : {ml_metrics['test_mae']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fonction de Prédiction ML\n",
    "\n",
    "Création d'une fonction pour prédire le temps de trajet entre deux points en utilisant le modèle ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_travel_time_ml(model, scaler, start_point, end_point, \n",
    "                          congestion=0.5, has_obstacles=0, n_obstacles_near=0,\n",
    "                          n_robots=5, obstacle_density=0.1):\n",
    "    \"\"\"\n",
    "    Prédire le temps de trajet entre deux points avec le modèle ML.\n",
    "    \n",
    "    Args:\n",
    "        model: Modèle ML entraîné\n",
    "        scaler: StandardScaler (None si RandomForest)\n",
    "        start_point: Tuple (x, y) du point de départ\n",
    "        end_point: Tuple (x, y) du point d'arrivée\n",
    "        congestion: Niveau de congestion (0.0 à 1.0)\n",
    "        has_obstacles: Présence d'obstacles (0 ou 1)\n",
    "        n_obstacles_near: Nombre d'obstacles proches\n",
    "        n_robots: Nombre de robots dans l'entrepôt\n",
    "        obstacle_density: Densité d'obstacles (0.0 à 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Temps de trajet prédit\n",
    "    \"\"\"\n",
    "    start_x, start_y = start_point\n",
    "    end_x, end_y = end_point\n",
    "    \n",
    "    # Calculer la distance\n",
    "    distance = euclidean_distance(start_point, end_point)\n",
    "    \n",
    "    # Préparer les features\n",
    "    features = np.array([[start_x, start_y, end_x, end_y, distance,\n",
    "                         congestion, has_obstacles, n_obstacles_near,\n",
    "                         n_robots, obstacle_density]])\n",
    "    \n",
    "    # Normaliser si nécessaire (pour MLP)\n",
    "    if scaler is not None:\n",
    "        features = scaler.transform(features)\n",
    "    \n",
    "    # Prédire\n",
    "    predicted_time = model.predict(features)[0]\n",
    "    \n",
    "    return predicted_time\n",
    "\n",
    "print(\"Fonction de prédiction ML créée\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construction de la Matrice de Coûts ML\n",
    "\n",
    "Création d'une nouvelle matrice de coûts basée sur les prédictions ML au lieu de la distance brute.\n",
    "\n",
    "**Stratégie pour corriger les chemins congestionnés** :\n",
    "- La congestion varie selon les zones (zones centrales = plus congestionnées)\n",
    "- Les chemins passant par des zones congestionnées ont un coût ML plus élevé\n",
    "- OR-Tools choisira donc des chemins alternatifs moins congestionnés\n",
    "- Cela garantit que les routes ML et baseline seront différentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour la prédiction ML\n",
    "# Ces valeurs peuvent être ajustées selon le scénario\n",
    "n_robots = 5  # Nombre de robots dans l'entrepôt\n",
    "base_congestion = 0.5  # Congestion de base\n",
    "obstacle_density = 0.1  # Densité d'obstacles\n",
    "\n",
    "def build_ml_cost_matrix(points, model, scaler, n_robots, base_congestion, obstacle_density):\n",
    "    \"\"\"\n",
    "    Construire une matrice de coûts basée sur les prédictions ML.\n",
    "    La congestion varie selon les zones pour que le ML puisse éviter les chemins congestionnés.\n",
    "    \n",
    "    Args:\n",
    "        points: Liste de points (x, y)\n",
    "        model: Modèle ML\n",
    "        scaler: StandardScaler ou None\n",
    "        n_robots: Nombre de robots\n",
    "        base_congestion: Congestion de base\n",
    "        obstacle_density: Densité d'obstacles\n",
    "    \n",
    "    Returns:\n",
    "        Matrice de coûts (predicted_time)\n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    ml_cost_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # Créer une carte de congestion variable selon les zones\n",
    "    # Les zones centrales sont plus congestionnées\n",
    "    width = max(p[0] for p in points)\n",
    "    height = max(p[1] for p in points)\n",
    "    center_x, center_y = width / 2, height / 2\n",
    "    \n",
    "    print(\"Construction de la matrice de coûts ML...\")\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                # Calculer la congestion locale basée sur la position\n",
    "                # Les zones centrales sont plus congestionnées\n",
    "                mid_x = (points[i][0] + points[j][0]) / 2\n",
    "                mid_y = (points[i][1] + points[j][1]) / 2\n",
    "                \n",
    "                # Distance du centre (zones centrales = plus congestionnées)\n",
    "                dist_from_center = np.sqrt((mid_x - center_x)**2 + (mid_y - center_y)**2)\n",
    "                max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "                \n",
    "                # Congestion varie de base_congestion à base_congestion + 0.4\n",
    "                # Plus proche du centre = plus congestionné\n",
    "                congestion_factor = 1.0 - (dist_from_center / max_dist) * 0.5\n",
    "                congestion = min(1.0, base_congestion + congestion_factor * 0.4 + (n_robots / 20) * 0.2)\n",
    "                \n",
    "                # Détecter les obstacles de manière déterministe basée sur la position\n",
    "                # Les zones avec beaucoup de points proches ont plus d'obstacles\n",
    "                nearby_points = sum(1 for k, p in enumerate(points) \n",
    "                                   if k != i and k != j and \n",
    "                                   euclidean_distance((mid_x, mid_y), p) < 3.0)\n",
    "                has_obstacles = 1 if nearby_points > 2 or obstacle_density > 0.15 else 0\n",
    "                n_obstacles_near = min(10, nearby_points)\n",
    "                \n",
    "                # Prédire le temps de trajet\n",
    "                predicted_time = predict_travel_time_ml(\n",
    "                    model, scaler,\n",
    "                    points[i], points[j],\n",
    "                    congestion=congestion,\n",
    "                    has_obstacles=has_obstacles,\n",
    "                    n_obstacles_near=n_obstacles_near,\n",
    "                    n_robots=n_robots,\n",
    "                    obstacle_density=obstacle_density\n",
    "                )\n",
    "                \n",
    "                # Convertir en entier pour OR-Tools\n",
    "                ml_cost_matrix[i, j] = int(predicted_time * 100)  # Multiplier par 100 pour précision\n",
    "    \n",
    "    return ml_cost_matrix\n",
    "\n",
    "# Construire la matrice de coûts ML\n",
    "ml_cost_matrix = build_ml_cost_matrix(\n",
    "    points, ml_model, scaler, n_robots, base_congestion, obstacle_density\n",
    ")\n",
    "\n",
    "print(f\"\\nMatrice de coûts ML construite : {ml_cost_matrix.shape}\")\n",
    "print(f\"Coûts min : {ml_cost_matrix[ml_cost_matrix > 0].min():.0f}\")\n",
    "print(f\"Coûts max : {ml_cost_matrix.max():.0f}\")\n",
    "print(f\"Coûts moyen : {ml_cost_matrix[ml_cost_matrix > 0].mean():.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation sans ML (baseline)\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTIMISATION SANS ML (BASELINE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_robots_optimization = 1  # TSP avec 1 robot\n",
    "optimizer_baseline = RouteOptimizer(\n",
    "    distance_matrix=distance_matrix.astype(int),\n",
    "    points=points,\n",
    "    point_labels=point_labels,\n",
    "    n_robots=n_robots_optimization,\n",
    "    depot_index=0\n",
    ")\n",
    "\n",
    "result_baseline = optimizer_baseline.solve(\n",
    "    search_strategy=\"PATH_CHEAPEST_ARC\",\n",
    "    time_limit_seconds=30\n",
    ")\n",
    "\n",
    "print(f\"\\nRésultats baseline (sans ML) :\")\n",
    "print(f\"  Distance totale : {optimizer_baseline.total_distance:.2f} unités\")\n",
    "print(f\"  Temps de résolution : {optimizer_baseline.solve_time:.3f} secondes\")\n",
    "print(f\"  Nombre de routes : {len(optimizer_baseline.routes)}\")\n",
    "\n",
    "# Calculer le temps de trajet total prédit par ML pour cette route baseline\n",
    "# Utiliser la même logique que pour construire la matrice ML\n",
    "baseline_predicted_time = 0\n",
    "width = max(p[0] for p in points)\n",
    "height = max(p[1] for p in points)\n",
    "center_x, center_y = width / 2, height / 2\n",
    "max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "\n",
    "for route in optimizer_baseline.routes:\n",
    "    for i in range(len(route) - 1):\n",
    "        from_node = route[i]\n",
    "        to_node = route[i + 1]\n",
    "        \n",
    "        # Même logique de congestion que dans build_ml_cost_matrix\n",
    "        mid_x = (points[from_node][0] + points[to_node][0]) / 2\n",
    "        mid_y = (points[from_node][1] + points[to_node][1]) / 2\n",
    "        dist_from_center = np.sqrt((mid_x - center_x)**2 + (mid_y - center_y)**2)\n",
    "        congestion_factor = 1.0 - (dist_from_center / max_dist) * 0.5\n",
    "        congestion = min(1.0, base_congestion + congestion_factor * 0.4 + (n_robots / 20) * 0.2)\n",
    "        \n",
    "        nearby_points = sum(1 for k, p in enumerate(points) \n",
    "                           if k != from_node and k != to_node and \n",
    "                           euclidean_distance((mid_x, mid_y), p) < 3.0)\n",
    "        has_obstacles = 1 if nearby_points > 2 or obstacle_density > 0.15 else 0\n",
    "        n_obstacles_near = min(10, nearby_points)\n",
    "        \n",
    "        predicted_time = predict_travel_time_ml(\n",
    "            ml_model, scaler,\n",
    "            points[from_node], points[to_node],\n",
    "            congestion=congestion,\n",
    "            has_obstacles=has_obstacles,\n",
    "            n_obstacles_near=n_obstacles_near,\n",
    "            n_robots=n_robots,\n",
    "            obstacle_density=obstacle_density\n",
    "        )\n",
    "        baseline_predicted_time += predicted_time\n",
    "\n",
    "print(f\"  Temps de trajet prédit (ML) pour cette route : {baseline_predicted_time:.2f} unités\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimisation Avec ML\n",
    "\n",
    "Relançons l'optimisation OR-Tools avec la nouvelle matrice de coûts basée sur les prédictions ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation avec ML\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTIMISATION AVEC ML\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "optimizer_ml = RouteOptimizer(\n",
    "    distance_matrix=ml_cost_matrix,\n",
    "    points=points,\n",
    "    point_labels=point_labels,\n",
    "    n_robots=n_robots_optimization,\n",
    "    depot_index=0\n",
    ")\n",
    "\n",
    "result_ml = optimizer_ml.solve(\n",
    "    search_strategy=\"PATH_CHEAPEST_ARC\",\n",
    "    time_limit_seconds=30\n",
    ")\n",
    "\n",
    "print(f\"\\nRésultats avec ML :\")\n",
    "print(f\"  Coût total (predicted_time) : {optimizer_ml.total_distance / 100:.2f} unités\")\n",
    "print(f\"  Temps de résolution : {optimizer_ml.solve_time:.3f} secondes\")\n",
    "print(f\"  Nombre de routes : {len(optimizer_ml.routes)}\")\n",
    "\n",
    "# Calculer la distance totale réelle pour la route ML\n",
    "ml_route_distance = 0\n",
    "for route in optimizer_ml.routes:\n",
    "    for i in range(len(route) - 1):\n",
    "        from_node = route[i]\n",
    "        to_node = route[i + 1]\n",
    "        ml_route_distance += euclidean_distance(points[from_node], points[to_node])\n",
    "\n",
    "print(f\"  Distance totale réelle : {ml_route_distance:.2f} unités\")\n",
    "\n",
    "# Calculer le temps de trajet total prédit par ML pour cette route ML\n",
    "ml_predicted_time = optimizer_ml.total_distance / 100  # Diviser par 100 car on a multiplié\n",
    "print(f\"  Temps de trajet prédit (ML) : {ml_predicted_time:.2f} unités\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison des Résultats\n",
    "\n",
    "Comparaison détaillée des deux approches avec toutes les métriques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison détaillée\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARAISON BASELINE vs ML\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_data = {\n",
    "    'Métrique': [\n",
    "        'Total Distance (unités)',\n",
    "        'Total Predicted Time (unités)',\n",
    "        'Temps de résolution (s)',\n",
    "        'Nombre de routes'\n",
    "    ],\n",
    "    'Sans ML (Baseline)': [\n",
    "        f\"{optimizer_baseline.total_distance:.2f}\",\n",
    "        f\"{baseline_predicted_time:.2f}\",\n",
    "        f\"{optimizer_baseline.solve_time:.3f}\",\n",
    "        f\"{len(optimizer_baseline.routes)}\"\n",
    "    ],\n",
    "    'Avec ML': [\n",
    "        f\"{ml_route_distance:.2f}\",\n",
    "        f\"{ml_predicted_time:.2f}\",\n",
    "        f\"{optimizer_ml.solve_time:.3f}\",\n",
    "        f\"{len(optimizer_ml.routes)}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Calculer les différences\n",
    "distance_diff = ((ml_route_distance - optimizer_baseline.total_distance) / optimizer_baseline.total_distance) * 100\n",
    "time_diff = ((ml_predicted_time - baseline_predicted_time) / baseline_predicted_time) * 100\n",
    "\n",
    "print(f\"\\nDifférences (%) :\")\n",
    "print(f\"  Distance : {distance_diff:+.2f}%\")\n",
    "print(f\"  Temps prédit : {time_diff:+.2f}%\")\n",
    "\n",
    "# Analyse\n",
    "print(f\"\\nAnalyse :\")\n",
    "if time_diff < 0:\n",
    "    print(f\"  La route ML est {abs(time_diff):.2f}% plus rapide en temps prédit\")\n",
    "elif abs(time_diff) < 5:\n",
    "    print(f\"  Les deux routes sont équivalentes (différence < 5%)\")\n",
    "else:\n",
    "    print(f\"  La route baseline est {time_diff:.2f}% plus rapide\")\n",
    "\n",
    "if distance_diff < 0:\n",
    "    print(f\"  La route ML est {abs(distance_diff):.2f}% plus courte en distance\")\n",
    "elif abs(distance_diff) < 5:\n",
    "    print(f\"  Les distances sont équivalentes (différence < 5%)\")\n",
    "else:\n",
    "    print(f\"  La route baseline est {abs(distance_diff):.2f}% plus courte\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisation des Deux Routes\n",
    "\n",
    "Visualisation côte à côte des routes optimisées avec et sans ML pour voir les différences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des deux routes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "all_x = [p[0] for p in points]\n",
    "all_y = [p[1] for p in points]\n",
    "\n",
    "# Route Baseline (sans ML)\n",
    "ax = axes[0]\n",
    "# Plot all points\n",
    "robot_indices = [i for i, label in enumerate(point_labels) if label.startswith(\"robot\")]\n",
    "pickup_indices = [i for i, label in enumerate(point_labels) if label.startswith(\"pickup\")]\n",
    "delivery_indices = [i for i, label in enumerate(point_labels) if label.startswith(\"delivery\")]\n",
    "\n",
    "if robot_indices:\n",
    "    ax.scatter([all_x[i] for i in robot_indices], [all_y[i] for i in robot_indices],\n",
    "              c='blue', s=200, marker='s', label='Robots', zorder=10, edgecolors='black', linewidths=2)\n",
    "if pickup_indices:\n",
    "    ax.scatter([all_x[i] for i in pickup_indices], [all_y[i] for i in pickup_indices],\n",
    "              c='green', s=120, marker='o', label='Pick-up Points', zorder=9, edgecolors='black', linewidths=1.5)\n",
    "if delivery_indices:\n",
    "    ax.scatter([all_x[i] for i in delivery_indices], [all_y[i] for i in delivery_indices],\n",
    "              c='red', s=120, marker='^', label='Delivery Stations', zorder=9, edgecolors='black', linewidths=1.5)\n",
    "\n",
    "# Plot baseline route\n",
    "for route in optimizer_baseline.routes:\n",
    "    route_x = [all_x[node] for node in route]\n",
    "    route_y = [all_y[node] for node in route]\n",
    "    ax.plot(route_x, route_y, color='steelblue', linewidth=2.5, alpha=0.7, zorder=5, label='Route Baseline')\n",
    "\n",
    "ax.set_xlabel('X Coordinate', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate', fontsize=12)\n",
    "ax.set_title(f'Route Optimisée SANS ML\\nDistance: {optimizer_baseline.total_distance:.2f} | Temps prédit: {baseline_predicted_time:.2f}', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Route ML\n",
    "ax = axes[1]\n",
    "# Plot all points (same)\n",
    "if robot_indices:\n",
    "    ax.scatter([all_x[i] for i in robot_indices], [all_y[i] for i in robot_indices],\n",
    "              c='blue', s=200, marker='s', label='Robots', zorder=10, edgecolors='black', linewidths=2)\n",
    "if pickup_indices:\n",
    "    ax.scatter([all_x[i] for i in pickup_indices], [all_y[i] for i in pickup_indices],\n",
    "              c='green', s=120, marker='o', label='Pick-up Points', zorder=9, edgecolors='black', linewidths=1.5)\n",
    "if delivery_indices:\n",
    "    ax.scatter([all_x[i] for i in delivery_indices], [all_y[i] for i in delivery_indices],\n",
    "              c='red', s=120, marker='^', label='Delivery Stations', zorder=9, edgecolors='black', linewidths=1.5)\n",
    "\n",
    "# Plot ML route\n",
    "for route in optimizer_ml.routes:\n",
    "    route_x = [all_x[node] for node in route]\n",
    "    route_y = [all_y[node] for node in route]\n",
    "    ax.plot(route_x, route_y, color='coral', linewidth=2.5, alpha=0.7, zorder=5, label='Route ML')\n",
    "\n",
    "ax.set_xlabel('X Coordinate', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate', fontsize=12)\n",
    "ax.set_title(f'Route Optimisée AVEC ML\\nDistance: {ml_route_distance:.2f} | Temps prédit: {ml_predicted_time:.2f}', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/processed/routes_comparison_ml.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualisation sauvegardée : ../data/processed/routes_comparison_ml.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse Détaillée des Métriques\n",
    "\n",
    "Analyse approfondie des métriques avec visualisations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des métriques\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Graphique 1 : Comparaison des distances et temps\n",
    "metrics_names = ['Distance\\nTotale', 'Temps Prédit\\n(ML)']\n",
    "baseline_values = [optimizer_baseline.total_distance, baseline_predicted_time]\n",
    "ml_values = [ml_route_distance, ml_predicted_time]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, baseline_values, width, label='Sans ML', color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].bar(x + width/2, ml_values, width, label='Avec ML', color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('Valeur', fontsize=12)\n",
    "axes[0].set_title('Comparaison des Métriques', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_names)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Graphique 2 : Différences en pourcentage\n",
    "diff_metrics = ['Distance', 'Temps Prédit']\n",
    "diff_values = [distance_diff, time_diff]\n",
    "colors = ['green' if v < 0 else 'red' for v in diff_values]\n",
    "\n",
    "axes[1].barh(diff_metrics, diff_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].set_xlabel('Différence (%)', fontsize=12)\n",
    "axes[1].set_title('Différences Relatives (%)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for i, v in enumerate(diff_values):\n",
    "    axes[1].text(v + (1 if v > 0 else -1), i, f'{v:+.2f}%', \n",
    "                va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Résumé des métriques\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RÉSUMÉ DES MÉTRIQUES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Distance :\")\n",
    "print(f\"  Sans ML : {optimizer_baseline.total_distance:.2f} unités\")\n",
    "print(f\"  Avec ML : {ml_route_distance:.2f} unités\")\n",
    "print(f\"  Différence : {distance_diff:+.2f}%\")\n",
    "\n",
    "print(f\"\\nTotal Predicted Time :\")\n",
    "print(f\"  Sans ML : {baseline_predicted_time:.2f} unités\")\n",
    "print(f\"  Avec ML : {ml_predicted_time:.2f} unités\")\n",
    "print(f\"  Différence : {time_diff:+.2f}%\")\n",
    "\n",
    "print(f\"\\nConclusion :\")\n",
    "if time_diff < -5:\n",
    "    print(f\"  La route ML est significativement plus rapide ({abs(time_diff):.2f}% d'amélioration)\")\n",
    "    print(f\"     Le ML a réussi à éviter les chemins congestionnés\")\n",
    "elif time_diff < 0:\n",
    "    print(f\"  La route ML est légèrement plus rapide ({abs(time_diff):.2f}% d'amélioration)\")\n",
    "elif abs(time_diff) < 5:\n",
    "    print(f\"  Les deux routes sont équivalentes\")\n",
    "else:\n",
    "    print(f\"  Dans ce scénario, la route baseline est plus rapide\")\n",
    "    print(f\"     Cela peut arriver si la congestion est faible\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyse des Chemins Différents\n",
    "\n",
    "Comparaison détaillée des chemins empruntés par les deux routes pour identifier où le ML a fait des choix différents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les routes\n",
    "baseline_route = optimizer_baseline.routes[0]\n",
    "ml_route = optimizer_ml.routes[0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARAISON DES CHEMINS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nRoute Baseline (sans ML) :\")\n",
    "print(\" -> \".join([point_labels[node] for node in baseline_route]))\n",
    "\n",
    "print(f\"\\nRoute ML :\")\n",
    "print(\" -> \".join([point_labels[node] for node in ml_route]))\n",
    "\n",
    "# Identifier les différences\n",
    "baseline_set = set(baseline_route)\n",
    "ml_set = set(ml_route)\n",
    "\n",
    "if baseline_route == ml_route:\n",
    "    print(\"\\nLes deux routes sont identiques\")\n",
    "    print(\"   Cela peut arriver si la congestion est faible ou uniforme\")\n",
    "else:\n",
    "    print(\"\\nLes routes sont différentes\")\n",
    "    print(f\"   Le ML a choisi un chemin alternatif\")\n",
    "    \n",
    "    # Analyser les segments différents\n",
    "    baseline_segments = set(zip(baseline_route[:-1], baseline_route[1:]))\n",
    "    ml_segments = set(zip(ml_route[:-1], ml_route[1:]))\n",
    "    \n",
    "    different_segments = baseline_segments.symmetric_difference(ml_segments)\n",
    "    print(f\"\\nSegments différents : {len(different_segments)}\")\n",
    "    \n",
    "    if len(different_segments) > 0:\n",
    "        print(\"   Exemples de segments uniques :\")\n",
    "        for seg in list(different_segments)[:5]:\n",
    "            from_label = point_labels[seg[0]]\n",
    "            to_label = point_labels[seg[1]]\n",
    "            if seg in ml_segments:\n",
    "                print(f\"     ML uniquement : {from_label} -> {to_label}\")\n",
    "            else:\n",
    "                print(f\"     Baseline uniquement : {from_label} -> {to_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test avec Différents Niveaux de Congestion\n",
    "\n",
    "Testons l'impact du ML avec différents niveaux de congestion pour montrer que le ML corrige mieux les chemins congestionnés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester avec différents niveaux de congestion\n",
    "# Pour valider les consignes : Route ML doit être plus rapide dans les scénarios congestionnés\n",
    "# ou équivalente en cas normal\n",
    "congestion_levels = [0.2, 0.4, 0.6, 0.8]\n",
    "results_congestion = []\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST AVEC DIFFÉRENTS NIVEAUX DE CONGESTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Objectif : Vérifier que le ML est plus rapide en cas de congestion élevée\")\n",
    "print(\"           et équivalent en cas de congestion normale\")\n",
    "print()\n",
    "\n",
    "for congestion in congestion_levels:\n",
    "    print(f\"--- Congestion = {congestion:.1f} ---\")\n",
    "    \n",
    "    # Reconstruire la matrice ML avec ce niveau de congestion\n",
    "    ml_cost_matrix_test = build_ml_cost_matrix(\n",
    "        points, ml_model, scaler, n_robots, congestion, obstacle_density\n",
    "    )\n",
    "    \n",
    "    # Optimisation avec ML\n",
    "    optimizer_ml_test = RouteOptimizer(\n",
    "        distance_matrix=ml_cost_matrix_test,\n",
    "        points=points,\n",
    "        point_labels=point_labels,\n",
    "        n_robots=n_robots_optimization,\n",
    "        depot_index=0\n",
    "    )\n",
    "    optimizer_ml_test.solve(search_strategy=\"PATH_CHEAPEST_ARC\", time_limit_seconds=30)\n",
    "    \n",
    "    # Optimisation baseline (sans ML) pour ce scénario\n",
    "    optimizer_baseline_test = RouteOptimizer(\n",
    "        distance_matrix=distance_matrix.astype(int),\n",
    "        points=points,\n",
    "        point_labels=point_labels,\n",
    "        n_robots=n_robots_optimization,\n",
    "        depot_index=0\n",
    "    )\n",
    "    optimizer_baseline_test.solve(search_strategy=\"PATH_CHEAPEST_ARC\", time_limit_seconds=30)\n",
    "    \n",
    "    # Calculer le temps prédit par ML pour la route baseline (sans ML)\n",
    "    baseline_test_predicted_time = 0\n",
    "    width = max(p[0] for p in points)\n",
    "    height = max(p[1] for p in points)\n",
    "    center_x, center_y = width / 2, height / 2\n",
    "    max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "    \n",
    "    for route in optimizer_baseline_test.routes:\n",
    "        for i in range(len(route) - 1):\n",
    "            from_node = route[i]\n",
    "            to_node = route[i + 1]\n",
    "            mid_x = (points[from_node][0] + points[to_node][0]) / 2\n",
    "            mid_y = (points[from_node][1] + points[to_node][1]) / 2\n",
    "            dist_from_center = np.sqrt((mid_x - center_x)**2 + (mid_y - center_y)**2)\n",
    "            congestion_factor = 1.0 - (dist_from_center / max_dist) * 0.5\n",
    "            local_congestion = min(1.0, congestion + congestion_factor * 0.4 + (n_robots / 20) * 0.2)\n",
    "            nearby_points = sum(1 for k, p in enumerate(points) \n",
    "                               if k != from_node and k != to_node and \n",
    "                               euclidean_distance((mid_x, mid_y), p) < 3.0)\n",
    "            has_obstacles = 1 if nearby_points > 2 or obstacle_density > 0.15 else 0\n",
    "            n_obstacles_near = min(10, nearby_points)\n",
    "            \n",
    "            predicted_time = predict_travel_time_ml(\n",
    "                ml_model, scaler,\n",
    "                points[from_node], points[to_node],\n",
    "                congestion=local_congestion,\n",
    "                has_obstacles=has_obstacles,\n",
    "                n_obstacles_near=n_obstacles_near,\n",
    "                n_robots=n_robots,\n",
    "                obstacle_density=obstacle_density\n",
    "            )\n",
    "            baseline_test_predicted_time += predicted_time\n",
    "    \n",
    "    # Temps prédit pour la route ML\n",
    "    ml_test_predicted_time = optimizer_ml_test.total_distance / 100\n",
    "    \n",
    "    # Distance réelle pour les deux routes\n",
    "    baseline_test_distance = optimizer_baseline_test.total_distance\n",
    "    ml_test_distance = sum(euclidean_distance(points[optimizer_ml_test.routes[0][i]], \n",
    "                                              points[optimizer_ml_test.routes[0][i+1]])\n",
    "                           for i in range(len(optimizer_ml_test.routes[0])-1))\n",
    "    \n",
    "    # Amélioration en temps prédit (positif = ML est meilleur)\n",
    "    time_improvement = ((baseline_test_predicted_time - ml_test_predicted_time) / baseline_test_predicted_time) * 100\n",
    "    \n",
    "    results_congestion.append({\n",
    "        'Congestion': congestion,\n",
    "        'Distance Baseline': baseline_test_distance,\n",
    "        'Distance ML': ml_test_distance,\n",
    "        'Predicted Time Baseline': baseline_test_predicted_time,\n",
    "        'Predicted Time ML': ml_test_predicted_time,\n",
    "        'Amélioration (%)': time_improvement\n",
    "    })\n",
    "    \n",
    "    print(f\"  Baseline (sans ML) :\")\n",
    "    print(f\"    Distance : {baseline_test_distance:.2f}\")\n",
    "    print(f\"    Temps prédit : {baseline_test_predicted_time:.2f}\")\n",
    "    print(f\"  ML :\")\n",
    "    print(f\"    Distance : {ml_test_distance:.2f}\")\n",
    "    print(f\"    Temps prédit : {ml_test_predicted_time:.2f}\")\n",
    "    print(f\"  Amélioration ML : {time_improvement:+.2f}%\")\n",
    "    print()\n",
    "\n",
    "results_df = pd.DataFrame(results_congestion)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RÉSUMÉ PAR NIVEAU DE CONGESTION\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Graphique 1 : Amélioration selon la congestion\n",
    "ax = axes[0]\n",
    "ax.plot(results_df['Congestion'], results_df['Amélioration (%)'], \n",
    "       marker='o', linewidth=2, markersize=10, color='steelblue')\n",
    "ax.axhline(y=0, color='r', linestyle='--', linewidth=1, label='Ligne de référence (équivalence)')\n",
    "ax.set_xlabel('Niveau de Congestion', fontsize=12)\n",
    "ax.set_ylabel('Amélioration du Temps Prédit (%)', fontsize=12)\n",
    "ax.set_title('Impact du ML selon le Niveau de Congestion', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2 : Comparaison des temps prédits\n",
    "ax = axes[1]\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, results_df['Predicted Time Baseline'], width, \n",
    "       label='Baseline (sans ML)', color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.bar(x + width/2, results_df['Predicted Time ML'], width, \n",
    "       label='ML', color='coral', alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Niveau de Congestion', fontsize=12)\n",
    "ax.set_ylabel('Temps Prédit (unités)', fontsize=12)\n",
    "ax.set_title('Comparaison des Temps Prédits', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"{c:.1f}\" for c in results_df['Congestion']])\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalyse des performances :\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Vérifier les performances selon les consignes\n",
    "# Route ML doit être : plus rapide dans les scénarios congestionnés OU équivalente en cas normal\n",
    "\n",
    "high_congestion_results = results_df[results_df['Congestion'] >= 0.7]\n",
    "normal_congestion_results = results_df[results_df['Congestion'] < 0.5]\n",
    "\n",
    "if len(high_congestion_results) > 0:\n",
    "    avg_improvement_high = high_congestion_results['Amélioration (%)'].mean()\n",
    "    print(f\"Scénarios congestionnés (congestion >= 0.7) :\")\n",
    "    print(f\"  Amélioration moyenne : {avg_improvement_high:+.2f}%\")\n",
    "    if avg_improvement_high > 0:\n",
    "        print(f\"  PERFORMANCE VALIDEE : Route ML est plus rapide dans les scénarios congestionnés\")\n",
    "    else:\n",
    "        print(f\"  ATTENTION : Route ML n'est pas plus rapide dans les scénarios congestionnés\")\n",
    "\n",
    "if len(normal_congestion_results) > 0:\n",
    "    avg_improvement_normal = normal_congestion_results['Amélioration (%)'].mean()\n",
    "    print(f\"\\nScénarios normaux (congestion < 0.5) :\")\n",
    "    print(f\"  Amélioration moyenne : {avg_improvement_normal:+.2f}%\")\n",
    "    if abs(avg_improvement_normal) < 10:\n",
    "        print(f\"  PERFORMANCE VALIDEE : Route ML est équivalente en cas normal\")\n",
    "    else:\n",
    "        print(f\"  Route ML diffère significativement même en cas normal\")\n",
    "\n",
    "best_improvement = results_df.loc[results_df['Amélioration (%)'].idxmax()]\n",
    "worst_improvement = results_df.loc[results_df['Amélioration (%)'].idxmin()]\n",
    "\n",
    "print(f\"\\nRésumé global :\")\n",
    "print(f\"  Meilleure amélioration : {best_improvement['Amélioration (%)']:.2f}% à congestion = {best_improvement['Congestion']:.1f}\")\n",
    "print(f\"  Pire amélioration : {worst_improvement['Amélioration (%)']:.2f}% à congestion = {worst_improvement['Congestion']:.1f}\")\n",
    "\n",
    "# Vérification finale des consignes\n",
    "print(f\"\\nVerification des consignes de performance :\")\n",
    "if len(high_congestion_results) > 0 and avg_improvement_high > 0:\n",
    "    print(f\"  [OK] Route ML est plus rapide dans les scénarios congestionnés\")\n",
    "elif len(normal_congestion_results) > 0 and abs(avg_improvement_normal) < 10:\n",
    "    print(f\"  [OK] Route ML est équivalente en cas normal\")\n",
    "else:\n",
    "    print(f\"  [ATTENTION] Les performances ne respectent pas exactement les consignes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sauvegarde des Résultats\n",
    "\n",
    "Sauvegarde des résultats de l'intégration ML pour analyse future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les résultats\n",
    "output_dir = \"../data/processed\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Résultats de comparaison\n",
    "comparison_results = {\n",
    "    \"baseline\": {\n",
    "        \"total_distance\": float(optimizer_baseline.total_distance),\n",
    "        \"total_predicted_time\": float(baseline_predicted_time),\n",
    "        \"solve_time\": float(optimizer_baseline.solve_time),\n",
    "        \"route\": [int(node) for node in optimizer_baseline.routes[0]]\n",
    "    },\n",
    "    \"ml\": {\n",
    "        \"total_distance\": float(ml_route_distance),\n",
    "        \"total_predicted_time\": float(ml_predicted_time),\n",
    "        \"solve_time\": float(optimizer_ml.solve_time),\n",
    "        \"route\": [int(node) for node in optimizer_ml.routes[0]]\n",
    "    },\n",
    "    \"differences\": {\n",
    "        \"distance_diff_percent\": float(distance_diff),\n",
    "        \"time_diff_percent\": float(time_diff)\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"n_robots\": n_robots,\n",
    "        \"base_congestion\": base_congestion,\n",
    "        \"obstacle_density\": obstacle_density\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = os.path.join(output_dir, \"ml_integration_results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(comparison_results, f, indent=2)\n",
    "\n",
    "print(f\"Résultats sauvegardés : {results_path}\")\n",
    "\n",
    "# Sauvegarder aussi les résultats par niveau de congestion\n",
    "congestion_results_path = os.path.join(output_dir, \"ml_congestion_analysis.json\")\n",
    "with open(congestion_results_path, 'w') as f:\n",
    "    json.dump(results_congestion, f, indent=2)\n",
    "\n",
    "print(f\"Analyse de congestion sauvegardée : {congestion_results_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Objectif atteint : Intégration ML + OR-Tools\n",
    "\n",
    "L'intégration du modèle ML dans l'optimisation OR-Tools permet de :\n",
    "\n",
    "1. **Utiliser des temps de trajet prédits** au lieu de distances brutes\n",
    "2. **Éviter les chemins congestionnés** grâce aux prédictions ML\n",
    "3. **Optimiser le temps réel** plutôt que la distance géométrique\n",
    "\n",
    "### Résultats\n",
    "\n",
    "- **Deux routes différentes** : Le ML peut choisir des chemins alternatifs\n",
    "- **Amélioration dans les scénarios congestionnés** : Le ML privilégie les chemins moins congestionnés\n",
    "- **Métriques comparées** : Distance totale, temps prédit, différences en pourcentage\n",
    "\n",
    "### Performances\n",
    "\n",
    "Selon les consignes, la Route ML doit être :\n",
    "- **Plus rapide dans les scénarios congestionnés** : Le ML évite les chemins congestionnés\n",
    "- **Équivalente en cas normal** : En l'absence de congestion, les routes peuvent être similaires\n",
    "\n",
    "Les tests avec différents niveaux de congestion permettent de valider ces performances.\n",
    "\n",
    "### Utilisation\n",
    "\n",
    "Le modèle ML peut maintenant être intégré dans le système de routing pour améliorer l'efficacité globale de l'entrepôt Amazon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
